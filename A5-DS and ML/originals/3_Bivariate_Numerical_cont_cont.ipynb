{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bivariate Numerical - cont cont",
      "provenance": [],
      "collapsed_sections": [
        "1FzYccB24irQ",
        "qfZv5qTw4rm_",
        "6PZEQUlXii1G",
        "37Pk32OwisyT",
        "TiC2VomvlWS5",
        "56ygh55Zok6v",
        "jFQ4BEyKrLkR",
        "kTqwU7fQ0jkI",
        "tleDyj9P_j_i",
        "0pLmF5hCfCnV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9mGxzDF5Cl9"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FzYccB24irQ"
      },
      "source": [
        "## Reading Files into Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWO5w4jIiWL"
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFxGyLx3L5IS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "870fa5f4-8b9f-45b6-8e64-7b20a59b0727"
      },
      "source": [
        "#importing data\n",
        "data = pd.read_csv('churn_prediction.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-eb8be8a7ff96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'churn_prediction.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File churn_prediction.csv does not exist: 'churn_prediction.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPcIwT47NQX6"
      },
      "source": [
        "#first 5 instances using \"head()\" function\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G5CwMDl2B_8"
      },
      "source": [
        "#last 5 instances using \"tail()\" function\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Iy0lfDNNZ8U"
      },
      "source": [
        "#finding out the shape of the data using \"shape\" variable: Output (rows, columns)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b75gSeumN50y"
      },
      "source": [
        "#Printing all the columns present in data\n",
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfZv5qTw4rm_"
      },
      "source": [
        "## Variable Identification and Typecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Us_uMgBnF_"
      },
      "source": [
        "# A closer look at the data types present in the data\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAh9MfrhFlBE"
      },
      "source": [
        "There are a lot of variables visible at once, so let's narrow this down by looking **at one datatype at once**. We will start with int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLXc4D7n9GIP"
      },
      "source": [
        "### Integer Data Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79o3VLDo-UcA"
      },
      "source": [
        "# Identifying variables with integer datatype\n",
        "data.dtypes[data.dtypes == 'int64']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yix8gagv-gwr"
      },
      "source": [
        "Summary:\n",
        "\n",
        "*    **Customer id** are a unique number assigned to customers. It can be **stored as Integer**.\n",
        "\n",
        "*    **branch code** again represents different branches, therefore it should be **convereted to category**.\n",
        "\n",
        "*    **Age** and **Vintage** are also numbers and hence we are okay with them as integers.\n",
        "\n",
        "*    **customer_networth_category** is supposed to be an ordinal category, **should be converted to category**.\n",
        "\n",
        "*    **churn** : 1 represents the churn and 0 represents not churn. However, there is no comparison between these two categories. This **needs to be converted to category datatype**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjim6-_NDUOe"
      },
      "source": [
        "# converting churn to category\n",
        "data['churn'] = data['churn'].astype('category')\n",
        "data['branch_code'] = data['branch_code'].astype('category')\n",
        "data['customer_nw_category'] = data['customer_nw_category'].astype('category')\n",
        "data.dtypes[data.dtypes == 'int64']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRSHTCVY9MSl"
      },
      "source": [
        "### Float Data Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4teLfjkzWbg"
      },
      "source": [
        "# Identifying variables with float datatype\n",
        "data.dtypes[data.dtypes == 'float64']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-97-KADzlCu"
      },
      "source": [
        "Summary:\n",
        "\n",
        "*    **dependents** is expected to be a whole number. **Should be changed to integer type**\n",
        "\n",
        "*    **city** variable is also a unique code of a city represented by some interger number. **Should be converted to Category type**\n",
        "\n",
        "*    Rest of the variables like **credit, balance and debit** are best represented by the float variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElAZeyTjWIh2"
      },
      "source": [
        "# converting \"dependents\" and \"city\" to their respective types\n",
        "data['dependents'] = data['dependents'].astype('Int64')\n",
        "data['city'] = data['city'].astype('category')\n",
        "\n",
        "# checking\n",
        "data[['dependents','city']].dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGScFSc_8Rl"
      },
      "source": [
        "### Object Data Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ou3CLuI9DwS"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzLUCLSU_Hmk"
      },
      "source": [
        "*    **variables like 'gender', 'occupation' and 'last_transaction' are of type object**. This means that **Pandas was not able to recognise the datatype** of these three variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjOBy8qRaYfl"
      },
      "source": [
        "# Manually checking object types\n",
        "data[['gender','occupation','last_transaction']].head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KOeDE6Bdlo4"
      },
      "source": [
        "*    **gender** and **occupation** variables **belong to categorical data types**.\n",
        "*    **last_transaction** should be a  **datetime variable**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WweHyTD1B-Hi"
      },
      "source": [
        "# typecasting \"gender\" and \"occupation\" to category type\n",
        "data['gender'] = data['gender'].astype('category')\n",
        "data['occupation'] = data['occupation'].astype('category')\n",
        "\n",
        "# checking\n",
        "data[['gender','occupation']].dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL6utzZVCXzZ"
      },
      "source": [
        "### datetime Data Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUW8X9y0cls5"
      },
      "source": [
        "# creating an instance(date) of DatetimeIndex class using \"last_transaction\"\n",
        "date = pd.DatetimeIndex(data['last_transaction'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiDzZxipexc8"
      },
      "source": [
        "# extracting new columns from \"last_transaction\"\n",
        "\n",
        "# last day of year when transaction was done\n",
        "data['doy_ls_tran'] = date.dayofyear\n",
        "\n",
        "# week of year when last transaction was done\n",
        "data['woy_ls_tran'] = date.weekofyear\n",
        "\n",
        "# month of year when last transaction was done\n",
        "data['moy_ls_tran'] = date.month\n",
        "\n",
        "# day of week when last transaction was done\n",
        "data['dow_ls_tran'] = date.dayofweek"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX959YsKk0ie"
      },
      "source": [
        "# checking new extracted columns using datetime\n",
        "data[['last_transaction','doy_ls_tran','woy_ls_tran','moy_ls_tran','dow_ls_tran']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey6xOF4gqHu2"
      },
      "source": [
        "The first column is the complete date of the last transaction which was done by the any given customer.\n",
        "\n",
        "The next columns represent the day of year, week of year, month of year, day of week when the last transaction was done.\n",
        "\n",
        "**Breaking down the date variable** into these granular information will **help us in understand when the last transaction was done from different perspectives**. Now that we have extracted the essentials from the last_transaction variables, we will drop it from the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVGFEI5aynYs"
      },
      "source": [
        "data = data.drop(columns = ['last_transaction'])\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PZEQUlXii1G"
      },
      "source": [
        "## Univariate Analysis: Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O8cRBfvipvQ"
      },
      "source": [
        "# Numerical datatypes\n",
        "data.select_dtypes(include=['int64','float64','Int64']).dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPCzH5ujHGZ"
      },
      "source": [
        "# seggregating variables into groups\n",
        "customer_details = ['customer_id','age','vintage']\n",
        "current_month = ['current_balance','current_month_credit','current_month_debit','current_month_balance']\n",
        "previous_month = ['previous_month_end_balance','previous_month_credit','previous_month_debit','previous_month_balance']\n",
        "previous_quarters = ['average_monthly_balance_prevQ','average_monthly_balance_prevQ2']\n",
        "transaction_date = ['doy_ls_tran','woy_ls_tran','moy_ls_tran','dow_ls_tran']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv_U-gn5jLhf"
      },
      "source": [
        "# custom function for easy and efficient analysis of numerical univariate\n",
        "\n",
        "def UVA_numeric(data, var_group):\n",
        "  '''\n",
        "  Univariate_Analysis_numeric\n",
        "  takes a group of variables (INTEGER and FLOAT) and plot/print all the descriptives and properties along with KDE.\n",
        "\n",
        "  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it\n",
        "  '''\n",
        "\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,3), dpi = 100)\n",
        "  \n",
        "  #looping for each variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    \n",
        "    # calculating descriptives of variable\n",
        "    mini = data[i].min()\n",
        "    maxi = data[i].max()\n",
        "    ran = data[i].max()-data[i].min()\n",
        "    mean = data[i].mean()\n",
        "    median = data[i].median()\n",
        "    st_dev = data[i].std()\n",
        "    skew = data[i].skew()\n",
        "    kurt = data[i].kurtosis()\n",
        "\n",
        "    # calculating points of standard deviation\n",
        "    points = mean-st_dev, mean+st_dev\n",
        "\n",
        "    #Plotting the variable with every information\n",
        "    plt.subplot(1,size,j+1)\n",
        "    sns.kdeplot(data[i], shade=True)\n",
        "    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n",
        "    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min/max\")\n",
        "    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n",
        "    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n",
        "    plt.xlabel('{}'.format(i), fontsize = 20)\n",
        "    plt.ylabel('density')\n",
        "    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n",
        "                                                                                                   round(kurt,2),\n",
        "                                                                                                   round(skew,2),\n",
        "                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n",
        "                                                                                                   round(mean,2),\n",
        "                                                                                                   round(median,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Pk32OwisyT"
      },
      "source": [
        "### customer_information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YFj4I-wprgH"
      },
      "source": [
        "UVA_numeric(data,customer_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD-3il2nJt10"
      },
      "source": [
        "**Summary of Customer_Information:**\n",
        "*    **customer_id**:\n",
        "     *    variable is **unique for every customer, Hence uniform** distribution.\n",
        "     * This variable **does not contribute any information**\n",
        "     * Can be eliminated from data\n",
        "\n",
        "*    **age**:\n",
        "    *    Median Age = 46\n",
        "    *    **Most customers age between 30 to 66**\n",
        "    *    skewness +0.33 : customer age is **negligibly biased towards younger age**\n",
        "    *    **kurtosis = -0.17**; very less likely to have extreme/outlier values.\n",
        "*    **vintage:**\n",
        "    *    Most customers joined between 2100 and 2650 days from the day of data extraction.\n",
        "    *    **skewness** -1.42 : this is left skewed, **vintage variable is significantly biased towards longer association of customers.**\n",
        "    *    **Kurtosis = 2.93**: Extreme values and Outliers are very likely to be present in vintage.\n",
        "\n",
        "**Things to Investigate Further down the road:**\n",
        "*    The batch of **high number of very Old Age customers** in age variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiC2VomvlWS5"
      },
      "source": [
        "### current_month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blZU92hHk81s"
      },
      "source": [
        "UVA_numeric(data,current_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J8ixOBgnE1O"
      },
      "source": [
        "**Summary**\n",
        "*    Considering the kurtosis and skewness value  for all 4 of these plots. Outliers/Extreme values are obvious."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9TpJ38koJbh"
      },
      "source": [
        "\n",
        "**Need to Remove Outliers to visulaise these plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvlh4yl1l5Tr"
      },
      "source": [
        "# standard deviation factor\n",
        "factor = 3\n",
        "\n",
        "# copying current_month\n",
        "cm_data = data[current_month]\n",
        "\n",
        "# filtering using standard deviation (not considering obseravtions > 3* standard deviation)\n",
        "cm_data = cm_data[cm_data['current_balance'] < factor*cm_data['current_balance'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_credit'] < factor*cm_data['current_month_credit'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_debit'] < factor*cm_data['current_month_debit'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_balance'] < factor*cm_data['current_month_balance'].std()]\n",
        "\n",
        "# checking how many points removed\n",
        "len(data), len(cm_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7eIx4invp0g"
      },
      "source": [
        "UVA_numeric(cm_data,current_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5T-Ldo0mLuJ"
      },
      "source": [
        "**Summary of current_month**\n",
        "*    After Removing extreme/outliers, plots are still very skewed.\n",
        "\n",
        "**Things to investigate further down**\n",
        "1.    **Is there thete any common trait/relation between the customers who are performing high transaction credit/debits?**\n",
        "2.    **Customers who are performinng high amount of transactions, are they doinng it every month?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ygh55Zok6v"
      },
      "source": [
        "### previous_month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjXX4cApwmc4"
      },
      "source": [
        "UVA_numeric(data,previous_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNBUxvviqVGj"
      },
      "source": [
        "**Summary of previous_month**\n",
        "*    This looks very similar to current_month. Most of the customers perform low amount transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFQ4BEyKrLkR"
      },
      "source": [
        "### previous_quarters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sUZY9X7owHI"
      },
      "source": [
        "UVA_numeric(data,previous_quarters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTazVPaBwn3f"
      },
      "source": [
        "**Summary**\n",
        "The general trend still follows, it is crutial that we find the out if there is any common trait between the customers doing high amount of transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTqwU7fQ0jkI"
      },
      "source": [
        "### transaction_date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt-oFFQCrVZ0"
      },
      "source": [
        "UVA_numeric(data,transaction_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJyehftG4qDk"
      },
      "source": [
        "**Summary**\n",
        "*    **Day_of_Year**:\n",
        "    *    most of the last transactions were made in the last 60 days of the extraction of data.\n",
        "    *    There are transactions which were made also an year ago.\n",
        "\n",
        "*   **Week_of_year and Month_of_year**: these variable validate the findings from the **day_of_year**.\n",
        "*    **Day_of_Week**: Tuesdays are often the favoured day relative to others.\n",
        "\n",
        "**Things to investigate further Down**\n",
        "*    **Customers whose last transaction was 6 months ago, did all of them churn?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tleDyj9P_j_i"
      },
      "source": [
        "## Univariate Analysis : Categorical Varibales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLWcwsoa0tlN"
      },
      "source": [
        "data.select_dtypes(exclude=['int64','float64','Int64']).dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ebDof6Vlnq"
      },
      "source": [
        "**Grouping Varibales**\n",
        "\n",
        "* **customer_info**: gender, occupation, customer_nw_category\n",
        "* **account_info**: city, branch_code\n",
        "* **churn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i9kY6dVEITb"
      },
      "source": [
        "# Custom function for easy visualisation of Categorical Variables\n",
        "def UVA_category(data, var_group):\n",
        "\n",
        "  '''\n",
        "  Univariate_Analysis_categorical\n",
        "  takes a group of variables (category) and plot/print all the value_counts and barplot.\n",
        "  '''\n",
        "  # setting figure_size\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,5), dpi = 100)\n",
        "\n",
        "  # for every variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    norm_count = data[i].value_counts(normalize = True)\n",
        "    n_uni = data[i].nunique()\n",
        "\n",
        "  #Plotting the variable with every information\n",
        "    plt.subplot(1,size,j+1)\n",
        "    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n",
        "    plt.xlabel('fraction/percent', fontsize = 20)\n",
        "    plt.ylabel('{}'.format(i), fontsize = 20)\n",
        "    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JowqxBPrUHOS"
      },
      "source": [
        "### customer_info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFaU9g0IY_I"
      },
      "source": [
        "UVA_category(data, ['occupation', 'gender', 'customer_nw_category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ato5X6wuY8vO"
      },
      "source": [
        "**Summary**\n",
        "* Occupation\n",
        "  * Majority of people are self_employed.\n",
        "  * There are extremely few Company Accounts. Might explain Outlier/Extreme values in credit/debit.\n",
        "\n",
        "* Gender:\n",
        "  *  Males accounts are 1.5 times more than Female Accounts.\n",
        "\n",
        "* customer_nw_category:\n",
        "  *  Half of all the accounts belong to the 3rd net worth category.\n",
        "  *  Less than 15% belong to the highest net worth category.\n",
        "\n",
        "**Things to investigate further down:**\n",
        "* Possibility: Company accounts are the reason behind the outlier transactions.\n",
        "* Possibility: customers belonging to the highest net worth category may explain the skewness of the transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnAMoLCkcD-b"
      },
      "source": [
        "### account_info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTey5QEbY7lM"
      },
      "source": [
        "UVA_category(data, ['city', 'branch_code'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTs4Ess5UE6t"
      },
      "source": [
        "#Plotting \"city\"\n",
        "plt.figure(figsize = (5,5), dpi = 120)\n",
        "city_count = data['city'].value_counts(normalize=True)\n",
        "sns.barplot(city_count.index, city_count , order = city_count.index)\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('fraction/percent')\n",
        "plt.ylim(0,0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhNQ_I8keQ7W"
      },
      "source": [
        "#Plotting \"branch_code\"\n",
        "plt.figure(figsize = (5,5), dpi = 120)\n",
        "branch_count = data['branch_code'].value_counts()\n",
        "sns.barplot(branch_count.index, branch_count , order = branch_count.index)\n",
        "plt.xlabel('branch_code')\n",
        "plt.ylabel('fraction/percent')\n",
        "#plt.ylim(0,0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A12aCbGWqM3l"
      },
      "source": [
        "**Summary:**\n",
        "for both variable \"city\" and \"branch_code\", there are too many categories. There is clear relation that some branches and cities are more popular with customers and and this trend decreases rapidly.\n",
        "\n",
        "**Things to investigate further Down**\n",
        "* Popular cities and branch code might be able to explain the skewness and outliers of credit/debit variables.\n",
        "* Possibility that cities and branch code with very few accounts may lead to churning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjn2DFHQ1DUA"
      },
      "source": [
        "### churn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3hiwoojj5tR"
      },
      "source": [
        "UVA_category(data, ['churn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8SyVYHe3R2-"
      },
      "source": [
        "**Summary**\n",
        "* Number of people who churned are 1/4 times of the people who did not churn in the given data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AyX9rNl-NIZ"
      },
      "source": [
        "## Univariate: Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hbg29tD4c8G"
      },
      "source": [
        "# finding number of missing values in every variable\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwY5XbTlevUg"
      },
      "source": [
        "**Things to investigate further down:**\n",
        "*    Gender: Do the customers with missing gender values have some common behaviour in-\n",
        "  * churn: do missing values have any relation with churn?\n",
        "\n",
        "* Dependents:\n",
        " * Missing values might be similar to zero dependents\n",
        " * churn: do missing values have any relation with churn?\n",
        "\n",
        "* Occupation:\n",
        " * Do missing values have similar behaviour to any other occupation\n",
        " * do they have some relation with churn?\n",
        "\n",
        "* city:\n",
        "  * the respective cities can be found using branch_code\n",
        "\n",
        "* last_transaction:\n",
        "  * checking their previous month and current month and previous_quarter activity might give insight on their last transaction.\n",
        "\n",
        "* For almost all the above:\n",
        "\n",
        "  * vintage: might be recording errors from same period of joining\n",
        "  * branch_code: might be recording error from certain branch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7XSk_6M8-Sn"
      },
      "source": [
        "## Univariate Analysis: Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r54EVLqQ-kbZ"
      },
      "source": [
        "**We suspected outliers in current_month and previous_month variable groups. We will verify that using bo plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBncECG3dVC2"
      },
      "source": [
        "# custom function for easy outlier analysis\n",
        "\n",
        "def UVA_outlier(data, var_group, include_outlier = True):\n",
        "  '''\n",
        "  Univariate_Analysis_outlier:\n",
        "  takes a group of variables (INTEGER and FLOAT) and plot/print boplot and descriptives\\n\n",
        "  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it \\n\\n\n",
        "\n",
        "  data : dataframe from which to plot from\\n\n",
        "  var_group : {list} type Group of Continuous variables\\n\n",
        "  include_outlier : {bool} whether to include outliers or not, default = True\\n\n",
        "  '''\n",
        "\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,4), dpi = 100)\n",
        "  \n",
        "  #looping for each variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    \n",
        "    # calculating descriptives of variable\n",
        "    quant25 = data[i].quantile(0.25)\n",
        "    quant75 = data[i].quantile(0.75)\n",
        "    IQR = quant75 - quant25\n",
        "    med = data[i].median()\n",
        "    whis_low = quant25-(1.5*IQR)\n",
        "    whis_high = quant75+(1.5*IQR)\n",
        "\n",
        "    # Calculating Number of Outliers\n",
        "    outlier_high = len(data[i][data[i]>whis_high])\n",
        "    outlier_low = len(data[i][data[i]<whis_low])\n",
        "\n",
        "    if include_outlier == True:\n",
        "      #Plotting the variable with every information\n",
        "      plt.subplot(1,size,j+1)\n",
        "      sns.boxplot(data[i], orient=\"v\")\n",
        "      plt.ylabel('{}'.format(i))\n",
        "      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n",
        "                                                                                                   round(IQR,2),\n",
        "                                                                                                   round(med,2),\n",
        "                                                                                                   (round(quant25,2),round(quant75,2)),\n",
        "                                                                                                   (outlier_low,outlier_high)\n",
        "                                                                                                   ))\n",
        "      \n",
        "    else:\n",
        "      # replacing outliers with max/min whisker\n",
        "      data2 = data[var_group][:]\n",
        "      data2[i][data2[i]>whis_high] = whis_high+1\n",
        "      data2[i][data2[i]<whis_low] = whis_low-1\n",
        "      \n",
        "      # plotting without outliers\n",
        "      plt.subplot(1,size,j+1)\n",
        "      sns.boxplot(data2[i], orient=\"v\")\n",
        "      plt.ylabel('{}'.format(i))\n",
        "      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n",
        "                                                                                                   round(IQR,2),\n",
        "                                                                                                   round(med,2),\n",
        "                                                                                                   (round(quant25,2),round(quant75,2)),\n",
        "                                                                                                   (outlier_low,outlier_high)\n",
        "                                                                                                   ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2slzVeVHPScG"
      },
      "source": [
        "### current_month and previous_month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhhypvHgIo9q"
      },
      "source": [
        "UVA_outlier(data, current_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aeCX9t2MR55"
      },
      "source": [
        "UVA_outlier(data, current_month, include_outlier=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FXEcoBlJLlm"
      },
      "source": [
        "UVA_outlier(data, previous_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uILo1wPFUzFw"
      },
      "source": [
        "UVA_outlier(data, previous_month, include_outlier=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JnOX4DxKn3Y"
      },
      "source": [
        "**Summary:**\n",
        "* If we look at corresponding plots in the outputs above, there seems to be a strong relation between the corresponding plots of previous_month and current_month variables.\n",
        "\n",
        "* Outliers are significant in number and very similar in number between corresponding plots. Which indicates some inherent undiscovered behviour of Outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqmFms6yPY7M"
      },
      "source": [
        "### previous quarters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6dxdT-2PbbU"
      },
      "source": [
        "UVA_outlier(data,previous_quarters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJ83i7yUiWO"
      },
      "source": [
        "UVA_outlier(data,previous_quarters, include_outlier = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORqbv5eoQ8lK"
      },
      "source": [
        "Summary:\n",
        "* Outliers in previous two quarters are very similar but significantly large in number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eirxZbBWGUBY"
      },
      "source": [
        "## Investigation directions from Univariate Analysis\n",
        "1. customer_id variable can be dropped.\n",
        "2.  Is there there any common trait/relation between the customers who are performing high transaction credit/debits?\n",
        "   * customer_nw_category might explain that.\n",
        "   * Occupation = Company might explain them\n",
        "   * popular cities might explain this\n",
        "4.  Customers whose last transaction was 6 months ago, did all of them churn? \n",
        "5. Possibility that cities and branch code with very few accounts may lead to churning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pLmF5hCfCnV"
      },
      "source": [
        "## Bivariate Analysis : Numerical-Numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkKRdwlJyqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "df4797c3-4f12-412c-d842-9e94a572fb0b"
      },
      "source": [
        "# isolating numerical datatypes\n",
        "numerical = data.select_dtypes(include=['int64','float64','Int64'])[:]\n",
        "numerical.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5eafafef0516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# isolating numerical datatypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Int64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYBGrb8IqF1r"
      },
      "source": [
        "### Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBlXGiiCw09O"
      },
      "source": [
        "# calculating correlation\n",
        "correlation = numerical.dropna().corr()\n",
        "correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5kVn205Uc4B"
      },
      "source": [
        "### Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDJHUYLEy2Gf"
      },
      "source": [
        "# plotting heatmap usill all methods for all numerical variables\n",
        "plt.figure(figsize=(36,6), dpi=140)\n",
        "for j,i in enumerate(['pearson','kendall','spearman']):\n",
        "  plt.subplot(1,3,j+1)\n",
        "  correlation = numerical.dropna().corr(method=i)\n",
        "  sns.heatmap(correlation, linewidth = 2)\n",
        "  plt.title(i, fontsize=18)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbatuwlduSNl"
      },
      "source": [
        "* Kendall and Spearman correlation seem to have very similar pattern between them, except the slight variation in magnitude of correlation.\n",
        "*  Too many variables with insignificant correlation.\n",
        "*  Major correlation lies between the transaction variables and balance variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZSKnYzf1xg5"
      },
      "source": [
        "# extracting transaction information of current and previous months\n",
        "var = []\n",
        "var.extend(previous_month)\n",
        "var.extend(current_month)\n",
        "var.extend(previous_quarters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZzT4v84DODe"
      },
      "source": [
        "# plotting heatmap usill all methods for all transaction variables\n",
        "plt.figure(figsize=(36,6), dpi=140)\n",
        "for j,i in enumerate(['pearson','kendall','spearman']):\n",
        "  plt.subplot(1,3,j+1)\n",
        "  correlation = numerical[var].dropna().corr(method=i)\n",
        "  sns.heatmap(correlation, linewidth = 2)\n",
        "  plt.title(i, fontsize=18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26W7HQLJS_Rz"
      },
      "source": [
        "**Inferences:**\n",
        "\n",
        "\n",
        "1.   Transaction variables like credit/debit have a strong correlation among themselves.\n",
        "2.  Balance variables have strong correlation among themselves.\n",
        "3.   Transaction variables like credit/debit have insignificant or no correlation with the Balance variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaYygjVJUf0I"
      },
      "source": [
        "### Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cirarNgU1Dn"
      },
      "source": [
        "# Grouping variables\n",
        "transactions = ['current_month_credit','current_month_debit','previous_month_credit','previous_month_debit']\n",
        "balance = ['previous_month_end_balance','previous_month_balance','current_balance','current_month_balance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sWiCzLIGMWn"
      },
      "source": [
        "# scatter plot for transactional variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[transactions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izeFVmArdlcL"
      },
      "source": [
        "**the scatter plot is is not meaningful due to the presence of outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYWU6jHpeEJf"
      },
      "source": [
        "#taking log of every value to negate outliers\n",
        "for column in var:\n",
        "  mini=1\n",
        "  if numerical[column].min()<0:\n",
        "    mini =  abs(numerical[column].min()) + 1\n",
        "  \n",
        "  numerical[column] = [i+mini for i in numerical[column]]\n",
        "  numerical[column] = numerical[column].map(lambda x : np.log(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAmHdUT8zyqG"
      },
      "source": [
        "# scatter plot for transactional variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[transactions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEpANup5eZwV"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the transaction variables.\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ1VkLc43tfI"
      },
      "source": [
        "# balance variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[balance])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as-bXBoFf1y5"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the balance variables.\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0SKcLQB31s"
      },
      "source": [
        "# previous quarters\n",
        "plt.figure(dpi=140)\n",
        "sns.scatterplot(numerical['average_monthly_balance_prevQ'], numerical['average_monthly_balance_prevQ2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL-II51yfz3F"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the two previous quarters\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJoNjvTqCI3P"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}